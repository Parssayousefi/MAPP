---
title: "MAPP"
author: "Parsa Yousefi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require("lavaan")) {
    install.packages("lavaan")
}
if (!require("pwr")) {
    install.packages("pwr")
}
if (!require("readxl")) {
    install.packages("readxl")
}
if (!require("ggplot2")) {
    install.packages("ggplot2")
}


library(lavaan)
library(readxl)
library(ggplot2)


```



#CFA

Load Data
```{r}
# Load the data
data <- HolzingerSwineford1939
data$school <- NULL
head(data)

```

#Preprocessing
```{r}
#sampel size estimate

#testing assumptions


# - Handling missing values
        #Full Information Maximum Likelihood
        #Multiple Imputation
# - Variable transformations
# - Normalization procedures (if applicable)

# Descriptive statistics, normality checks, etc.

# standardized residuals

#check each items if they are continious. 

```
#Contingency Assumption
```{r}
#What if assumptions are not met?

#Assumption: manifest endogenous variables follow a multivariate normal distribution
# if violated: use "robust estimators"


```

#CFA
```{r}
# assume data has one clumn for each item: MEQ1, MEQ2, ..., CEQ1, CEQ2, ..., AWE1, AWE2,
# and so on. The first column is the ID column, so we start at the second column (index 2)

# Constructing the model string
# Here we concatenate 'Mystic =~' with all item names, joined by ' + '

model_string <- paste("Mystic =~", paste(names(data)[2:length(names(data))], collapse=" + "))

# Print the model string to check it
# cat(modelString)

# Fit the model
fit_normal <- cfa(model_string, data = data, estimator = "ML")

# Summarize the fit
summary(fit_normal, fit.measures = TRUE, standardized = TRUE)
```

#check residuals
```{r}

# standardized residuals
residuals <- lavResiduals(fit_normal)
str(residuals)


# Extract the standardized residuals matrix
residuals_matrix <- residuals$cov.z

# Convert the matrix to a data frame
residuals_df <- as.data.frame(as.table(residuals_matrix))

# Rename the columns to match your ggplot aes
names(residuals_df) <- c("Variable1", "Variable2", "Residual")

# heat map of residuals indicate the magnitude and direction of the residuals,
ggplot(residuals_df, aes(x = Variable1, y = Variable2, fill = Residual)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  labs(title = "Standardized Residuals",
       x = "Item 1",
       y = "Item 2",
       fill = "Residual")
 
# histogram of residuals
ggplot(residuals_df, aes(x = Residual)) +
    geom_histogram(bins = 30, fill = "blue", color = "black") +
    theme_minimal() +
    labs(title = "Histogram of Standardized Residuals", x = "Standardized Residual", y = "Frequency")

#Plot Q-Q Plot of Residuals
qqnorm(residuals_df$Residual, main = "Q-Q Plot of Standardized Residuals")
qqline(residuals_df$Residual, col = "red")
```


#Hierarchical Model
```{r}


# Higher-order model specification 
model_hierarchical <- '
  # Specific factors for each questionnaire
  MEQ =~ MEQ1 + MEQ2 + ... + MEQ30
  CEQ =~ CEQ1 + CEQ2 + ... + CEQ26
  AWES =~ AWES1 + AWES2 + ... + AWES30
  ESAT =~ ESAT1 + ESAT2 + ... + ESAT18
  EDI =~ EDI1 + EDI2 + ... + EDI8
  SWLS =~ SWLS1 + SWLS2 + ... + SWLS5
  NADA_S =~ NADA_S1 + NADA_S2 + NADA_S3
  ASC11D =~ ASC11D1 + ASC11D2 + ... + ASC11D11
  ASC11DShort =~ ASC11DShort1
  EISI =~ EISI1 + EISI2 + ... + EISI25
  INOE =~ INOE1 + INOE2 + ... + INOE_lastItem
  APEQ_S =~ APEQ_S1 + APEQ_S2 + ... + APEQ_S12
  LAP =~ LAP1 + LAP2 + ... + LAP56
  APEI =~ APEI1 + APEI2 + ... + APEI_lastItem

  # General factor "Mystic" influencing all specific factors
  Mystic =~ MEQ + CEQ + AWES + ESAT + EDI + SWLS + NADA_S + ASC11D + ASC11DShort + INOE + EISI + APEQ_S + LAP + APEI
'

# Fit the hierarchical model 
fit_hierarchical <- cfa(model_hierarchical, data = data, estimator = "ML")

# Summarize the model fit and interpret the results
summary(fit_hierarchical, fit.measures = TRUE, standardized = TRUE)


```

#bi-factor Model
```{r}
# Bi-factor model specification
model_bifactor <- '
    # Specific factors for each questionnaire
  MEQ =~ MEQ1 + MEQ2 + ... 
  CEQ =~ a*CEQ1 + a*CEQ2 + ... 
  AWES =~ b*AWES1 + b*AWES2 + ...
  ESAT =~ c*ESAT1 + c*ESAT2 + ... 
  EDI =~ d* DI1 + d*EDI2 + ... 
  SWLS =~ e*SWLS1 + e*SWLS2 + ... 
  NADA =~ f*NADA1 + f*NADA2 + ... 
  ASC11D =~ g*ASC11D1 + g*ASC11D2 + ... 
  ASC11DShort =~ h*ASC11DShort1 
  EISI =~ i*EISI1 + i*EISI2 + ... 
  INOE =~ j*INOE1 + j*INOE2 + ... 
  APEQS =~ k*APEQS1 + k*APEQS2 + ... 
  LAP =~ l*LAP1 + l*LAP2 + ... 
  APEI =~ m*APEI1 + m*APEI2 + ... 
  

 # General factor "mystic" affecting all items
  #Mystic =~ MEQ1 + MEQ2 + ... + APEI_lastItem
  paste("Mystic =~", paste(names(data)[2:251], collapse=" + "))

'

# Fit the bi-factor model
# orthogonal = TRUE makes all exogenous LVs in the model uncorrelated
#because we constrained the loadings for the domain-specific LVs with only two indicator 
#If we do not use this argument, then all the constrained factor loadings are set to 1 
fit_bifactor <- cfa(model_bifactor, data = data, orthogonal = TRUE, std.lv=TRUE, estimator = "ML")

# Summarize the model fit and interpret the results
summary(fit_bifactor, fit.measures = TRUE, standardized = TRUE)
```	

# Compare the models
```{r}
# Models are nested! 
#From Most restrictive to least restrictive: CFA, Hierarchical, Bi-factor
anova( fit_normal, fit_hierarchical )
anova(fit_hierarchical, fit_bifactor)

```

#sum scores
```{r}

# fit sum scores 


```
#Sensitivity Analyses
```{r}
# Sensitivity analyses
# repeat with different methods or subsets of data?
```

#Contingency Fit
```{r}
#What if the initial model doesnt fit?


```

# What is the best predictor of well being?
```{r}
#Pseudocode

# Step 1: Perform Lasso Regression

# - Lasso regression to predict well-being .

# - Input: Dataset with variables potentially related to well-being.

# - Process: Apply Lasso regression to select relevant variables and predict well-being.

# - Output: Model that predicts well-being, including selected variables.

 

# Step 2: Correlational Analysis

# - Determine the correlation between each item (variable) and well-being.

# - Input: Dataset with items and well-being scores.

# - Process: Calculate correlation coefficients for each item with respect to well-being.

# - Output: List of items ranked by their correlation with well-being.

 

# Step 3: Fit 1 Factor Model for Well-being Questionnaires

# - Input: Responses to well-being questionnaires.

# - Process: Apply CFA to determine whether a 1 factor model fits the data.

# - Output: Fit emasures; factor loadings for each item.

 

# Step 4: Extract Factor Scores

# - If the 1 factor model is a good fit, calculate factor scores for each subject.

# - Input: Factor loadings and individual responses to questionnaires.

# - Process: Use the factor model to compute a score for each subject that represents their level of well-being.

# - Output: Factor scores for each subject ?
```
